"""
ìŠ¤ë§ˆíŠ¸ RAG ì‹œìŠ¤í…œ - AIê°€ ì§ˆë¬¸ì— ë”°ë¼ ì ì ˆí•œ ë¬¸ì„œë¥¼ ìë™ ì„ íƒ

í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
pip install langchain langchain-community langchain-openai langchain-chroma chromadb openai
"""
import os
import json
from pathlib import Path
from typing import List, Dict, Set

try:
    from langchain_community.document_loaders import TextLoader, DirectoryLoader
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_openai import OpenAIEmbeddings, ChatOpenAI
    from langchain_chroma import Chroma
    from langchain.chains import RetrievalQA
    from langchain.schema import Document
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ í•„ìš”:")
    print(f"   pip install langchain langchain-community langchain-openai langchain-chroma chromadb openai")
    raise ImportError(f"Missing required package: {e}")


class SmartDocumentSelector:
    """ì§ˆë¬¸ ë¶„ì„ í›„ ì ì ˆí•œ ë¬¸ì„œ ì¹´í…Œê³ ë¦¬ ì„ íƒ"""

    def __init__(self, metadata_path: str = "docs/doc_metadata.json"):
        self.metadata_path = Path(metadata_path)
        self.metadata = self._load_metadata()

    def _load_metadata(self) -> Dict:
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if not self.metadata_path.exists():
            print(f"âš ï¸  ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.metadata_path}")
            return {"categories": {}, "default_category": "general"}

        with open(self.metadata_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def analyze_query(self, query: str) -> List[str]:
        """
        ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ì¹´í…Œê³ ë¦¬ ë°˜í™˜

        Returns:
            ì¹´í…Œê³ ë¦¬ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ê´€ë ¨ë„ ìˆœ)
        """
        query_lower = query.lower()
        category_scores = {}

        for category, info in self.metadata['categories'].items():
            score = 0
            keywords = info['keywords']

            # í‚¤ì›Œë“œ ë§¤ì¹­
            for keyword in keywords:
                if keyword.lower() in query_lower:
                    score += 1

            if score > 0:
                category_scores[category] = score

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        if category_scores:
            sorted_categories = sorted(
                category_scores.items(),
                key=lambda x: x[1],
                reverse=True
            )
            selected = [cat for cat, score in sorted_categories]
            print(f"ğŸ¯ ì„ íƒëœ ì¹´í…Œê³ ë¦¬: {', '.join(selected)}")
            return selected
        else:
            default = self.metadata.get('default_category', 'general')
            print(f"ğŸ¯ ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©: {default}")
            return [default]

    def get_document_paths(self, categories: List[str], base_path: str = "docs") -> List[str]:
        """ì¹´í…Œê³ ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì„œ ê²½ë¡œ ë°˜í™˜"""
        paths = []
        base = Path(base_path)

        for category in categories:
            if category in self.metadata['categories']:
                files = self.metadata['categories'][category]['files']
                for file in files:
                    full_path = base / file
                    if full_path.exists():
                        paths.append(str(full_path))
                    else:
                        print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {full_path}")

        return paths


class SmartRAGSystem:
    """ìŠ¤ë§ˆíŠ¸ RAG ì‹œìŠ¤í…œ"""

    def __init__(self, docs_base_path: str = "docs"):
        self.docs_base_path = Path(docs_base_path)
        self.selector = SmartDocumentSelector()
        self.embeddings = OpenAIEmbeddings()
        self.llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len,
        )

    def load_documents(self, file_paths: List[str]) -> List[Document]:
        """ì§€ì •ëœ íŒŒì¼ë“¤ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
        documents = []

        for file_path in file_paths:
            try:
                loader = TextLoader(file_path, encoding='utf-8')
                docs = loader.load()
                documents.extend(docs)
                print(f"âœ… ë¡œë“œ: {Path(file_path).name}")
            except Exception as e:
                print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {file_path} - {e}")

        return documents

    def load_all_documents(self) -> List[Document]:
        """ëª¨ë“  ë¬¸ì„œ ë¡œë“œ (ì´ˆê¸° ë²¡í„° DB ìƒì„±ìš©)"""
        print(f"ğŸ“š ëª¨ë“  ë¬¸ì„œ ë¡œë”©: {self.docs_base_path}")

        documents = []
        for txt_file in self.docs_base_path.rglob("*.txt"):
            try:
                loader = TextLoader(str(txt_file), encoding='utf-8')
                docs = loader.load()
                documents.extend(docs)
                print(f"âœ… {txt_file.relative_to(self.docs_base_path)}")
            except Exception as e:
                print(f"âŒ {txt_file.name}: {e}")

        return documents

    def create_vectorstore(self, documents: List[Document], persist_dir: str = "./chroma_db") -> Chroma:
        """ë²¡í„° DB ìƒì„±"""
        print(f"âœ‚ï¸  {len(documents)}ê°œ ë¬¸ì„œë¥¼ ì²­í¬ë¡œ ë¶„í•  ì¤‘...")
        texts = self.text_splitter.split_documents(documents)
        print(f"âœ… {len(texts)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")

        print("ğŸ”¢ ë²¡í„° DB ìƒì„± ì¤‘...")
        vectorstore = Chroma.from_documents(
            documents=texts,
            embedding=self.embeddings,
            persist_directory=persist_dir
        )
        print("âœ… ë²¡í„° DB ìƒì„± ì™„ë£Œ")

        return vectorstore

    def create_qa_chain(self, vectorstore: Chroma, k: int = 3) -> RetrievalQA:
        """QA ì²´ì¸ ìƒì„±"""
        qa_chain = RetrievalQA.from_chain_type(
            llm=self.llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": k}),
            return_source_documents=True,
        )
        return qa_chain

    def ask_with_smart_selection(self, query: str, use_all: bool = False) -> Dict:
        """
        ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ì„ íƒ í›„ ì§ˆë¬¸ ì²˜ë¦¬

        Args:
            query: ì§ˆë¬¸
            use_all: Trueë©´ ëª¨ë“  ë¬¸ì„œ ì‚¬ìš©, Falseë©´ ê´€ë ¨ ë¬¸ì„œë§Œ ì„ íƒ
        """
        print(f"\nâ“ ì§ˆë¬¸: {query}")
        print("="*60)

        if use_all:
            print("ğŸ“š ëª¨ë“  ë¬¸ì„œ ì‚¬ìš© ëª¨ë“œ")
            documents = self.load_all_documents()
        else:
            print("ğŸ¯ ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ì„ íƒ ëª¨ë“œ")
            # ì§ˆë¬¸ ë¶„ì„
            categories = self.selector.analyze_query(query)

            # ê´€ë ¨ ë¬¸ì„œ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
            file_paths = self.selector.get_document_paths(categories, str(self.docs_base_path))

            if not file_paths:
                print("âš ï¸  ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª¨ë“  ë¬¸ì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                documents = self.load_all_documents()
            else:
                print(f"ğŸ“„ ì„ íƒëœ ë¬¸ì„œ ë¡œë”©...")
                documents = self.load_documents(file_paths)

        if not documents:
            return {"error": "ë¡œë“œëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."}

        # ë²¡í„° DB ìƒì„± (ì„ì‹œ)
        vectorstore = self.create_vectorstore(documents, persist_dir="./temp_chroma_db")

        # QA ì²´ì¸ ìƒì„± ë° ì§ˆë¬¸
        qa_chain = self.create_qa_chain(vectorstore)

        print("ğŸ’­ ìƒê° ì¤‘...\n")
        result = qa_chain.invoke({"query": query})

        # ê²°ê³¼ ì¶œë ¥
        print("ğŸ“ ë‹µë³€:")
        print("-" * 60)
        print(result["result"])
        print("-" * 60)

        if "source_documents" in result:
            print(f"\nğŸ“š ì°¸ì¡° ë¬¸ì„œ: {len(result['source_documents'])}ê°œ")
            # ì°¸ì¡°ëœ ê³ ìœ  íŒŒì¼ í‘œì‹œ
            sources = set()
            for doc in result['source_documents']:
                if 'source' in doc.metadata:
                    sources.add(Path(doc.metadata['source']).name)
            if sources:
                print(f"   íŒŒì¼: {', '.join(sources)}")

        return result


def setup_environment():
    """í™˜ê²½ ì„¤ì • ë° ê²€ì¦"""
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError(
            "OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\n"
            "ì„¤ì • ë°©ë²•: export OPENAI_API_KEY='your-api-key'"
        )
    return api_key


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ğŸš€ ìŠ¤ë§ˆíŠ¸ RAG ì‹œìŠ¤í…œ ì‹œì‘\n")

        # í™˜ê²½ ì„¤ì •
        setup_environment()

        # RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        rag = SmartRAGSystem(docs_base_path="docs")

        # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
        questions = [
            ("íšŒì‚¬ì˜ íŠ¸ë ˆì´ë”© ì „ëµì—ëŠ” ì–´ë–¤ ê²ƒë“¤ì´ ìˆë‚˜ìš”?", False),
            ("RSI ì§€í‘œëŠ” ì–´ë–»ê²Œ ì‚¬ìš©í•˜ë‚˜ìš”?", False),
            ("ë¦¬ìŠ¤í¬ ê´€ë¦¬ì—ì„œ ì†ì ˆë§¤ëŠ” ì–´ë–»ê²Œ ì„¤ì •í•˜ë‚˜ìš”?", False),
            ("íšŒì‚¬ì˜ ë¹„ì „ì€ ë¬´ì—‡ì¸ê°€ìš”?", False),
            ("ë³¼ë¦°ì € ë°´ë“œì™€ í¬ì§€ì…˜ ì‚¬ì´ì§•ì„ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”", True),  # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬
        ]

        for i, (question, use_all) in enumerate(questions, 1):
            print(f"\n{'='*60}")
            print(f"ì§ˆë¬¸ {i}/{len(questions)}")
            print(f"{'='*60}")

            result = rag.ask_with_smart_selection(question, use_all=use_all)

            if "error" not in result:
                print(f"\nâœ… ì§ˆë¬¸ {i} ì™„ë£Œ")
            else:
                print(f"\nâŒ ì§ˆë¬¸ {i} ì˜¤ë¥˜: {result['error']}")

        print("\n" + "="*60)
        print("âœ… ìŠ¤ë§ˆíŠ¸ RAG ë°ëª¨ ì™„ë£Œ!")
        print("="*60)

    except ValueError as e:
        print(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise


if __name__ == "__main__":
    main()
